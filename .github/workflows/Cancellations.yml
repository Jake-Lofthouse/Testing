name: Cancellations

on:
  schedule:
    - cron: "0 */2 * * *"  # Runs every 2 hours
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Install dependencies
        run: pip install requests beautifulsoup4

      # Notify Cronitor at the start of the workflow
      - name: Notify Cronitor start
        run: curl -m 10 --retry 5 -o /dev/null -s "https://cronitor.link/p/6c06f2554fc841ccb0b0928481a03ed1/cancellation-scraper/run"

      - name: Run cancellation scraper
        id: run_scraper
        run: |
          python "scripts/cancellations.py"
          echo "exit_code=$?" >> $GITHUB_ENV  # Save exit code to environment variable

      - name: Commit and push changes
        if: steps.run_scraper.outcome == 'success'
        run: |
          git config --global user.name 'github-actions'
          git config --global user.email 'actions@github.com'
          git add cancellations.json
          git commit -m "Update Parkrun cancellations"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Notify Cronitor based on exit status with conditions for success/failure
      - name: Notify Cronitor on exit status
        run: |
          if [ "$exit_code" -eq 0 ] || [ "$exit_code" -eq 1 ]; then
            # Success for exit code 0 or 1
            curl -m 10 --retry 5 -o /dev/null -s "https://cronitor.link/p/6c06f2554fc841ccb0b0928481a03ed1/cancellation-scraper/complete?msg=Success%20with%20exit%20code%20$exit_code"
          else
            # Failure for any other exit code
            curl -m 10 --retry 5 -o /dev/null -s "https://cronitor.link/p/6c06f2554fc841ccb0b0928481a03ed1/cancellation-scraper/fail?msg=Failure%20with%20exit%20code%20$exit_code"
          fi
